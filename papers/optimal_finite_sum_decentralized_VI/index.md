title: Optimal Algorithms for Decentralized Stochastic Variational Inequalities
date: 6 Feb 2022
abstract: Variational inequalities are a formalism that includes games, minimization, saddle point, and equilibrium problems as special cases. Methods for variational inequalities are therefore universal approaches for many applied tasks, including machine learning problems. This work concentrates on the decentralized setting, which is increasingly important but not well understood. In particular, we consider decentralized stochastic (sum-type) variational inequalities over fixed and time-varying networks. We present lower complexity bounds for both communication and local iterations and construct optimal algorithms that match these lower bounds. Our algorithms are the best among the available literature not only in the decentralized stochastic case, but also in the decentralized deterministic and non-distributed stochastic cases. Experimental results confirm the effectiveness of the presented algorithms.
authors:    Dmitry Kovalev
            Aleksandr Beznosikov
            Abdurakhmon Sadiev
            Michael Persiianov
            Peter Richt√°rik
            Alexander Gasnikov
links: {"PDF": "https://arxiv.org/pdf/2202.02771", "NeurIPS 2022": "https://papers.nips.cc/paper_files/paper/2022/hash/c959bb2cb164d37569a17fa67494d69a-Abstract-Conference.html", "arXiv" : "https://arxiv.org/abs/2202.02771"}