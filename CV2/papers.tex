\section{Publications}
\begin{enumerate}
\item \textbf{Is Consensus Acceleration Possible in Decentralized Optimization over Slowly Time-Varying Networks?} (\href{}{\color{linkcolour}Dmitriy Metelev}, \href{https://scholar.google.com/citations?user=sEjyzkgAAAAJ}{\color{linkcolour}Alexander Rogozin}, \href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}, \href{https://scholar.google.ru/citations?user=AmeE8qkAAAAJ}{\color{linkcolour}Alexander Gasnikov}), \href{https://openreview.net/forum?id=DwDQNKF4oy}{\em \color{black}ICML 2023}
\item \textbf{Accelerated Variance-Reduced Methods for Saddle-Point Problems} (\href{https://scholar.google.com/citations?user=9Dapoy8AAAAJ}{\color{linkcolour}Ekaterina Borodich}, \href{}{\color{linkcolour}Vladislav Tominin}, \href{}{\color{linkcolour}Yaroslav Tominin}, \href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}, \href{https://scholar.google.ru/citations?user=AmeE8qkAAAAJ}{\color{linkcolour}Alexander Gasnikov}, \href{http://wias-berlin.de/people/dvureche/}{\color{linkcolour}Pavel Dvurechensky}), \href{https://www.sciencedirect.com/science/article/pii/S2192440622000247}{\em \color{black}EURO Journal on Computational Optimization}
\item \textbf{Communication Acceleration of Local Gradient Methods via an Accelerated Primal-Dual Algorithm with Inexact Prox} (\href{https://scholar.google.com/citations?user=R-xZRIAAAAAJ&hl=ru}{\color{linkcolour}Abdurakhmon Sadiev}, \href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}, \href{https://richtarik.org}{\color{linkcolour}Peter Richtarik}), \href{https://papers.nips.cc/paper_files/paper/2022/hash/88c3c482430a62d35e03926a22e4b67e-Abstract-Conference.html}{\em \color{black}NeurIPS 2022}
\item \textbf{Optimal Gradient Sliding and its Application to Distributed Optimization Under Similarity} (\href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}, \href{https://anbeznosikov.github.io}{\color{linkcolour}Aleksandr Beznosikov}, \href{https://scholar.google.com/citations?user=9Dapoy8AAAAJ}{\color{linkcolour}Ekaterina Borodich}, \href{https://scholar.google.ru/citations?user=AmeE8qkAAAAJ}{\color{linkcolour}Alexander Gasnikov}, \href{https://engineering.purdue.edu/~gscutari/}{\color{linkcolour}Gesualdo Scutari}), \href{https://proceedings.neurips.cc/paper_files/paper/2022/hash/d88f6f81e1aaf606776ffdd06fdf24ef-Abstract-Conference.html}{\em \color{black}NeurIPS 2022}
\item \textbf{The First Optimal Acceleration of High-Order Methods in Smooth Convex Optimization} (\href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}, \href{https://scholar.google.ru/citations?user=AmeE8qkAAAAJ}{\color{linkcolour}Alexander Gasnikov}), \href{https://papers.nips.cc/paper_files/paper/2022/hash/e56f394bbd4f0ec81393d767caa5a31b-Abstract-Conference.html}{\em \color{black}NeurIPS 2022}
\item \textbf{The First Optimal Algorithm for Smooth and Strongly-Convex-Strongly-Concave Minimax Optimization} (\href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}, \href{https://scholar.google.ru/citations?user=AmeE8qkAAAAJ}{\color{linkcolour}Alexander Gasnikov}), \href{https://papers.nips.cc/paper_files/paper/2022/hash/5e2ed801f62102f531d109d7c6e1b62f-Abstract-Conference.html}{\em \color{black}NeurIPS 2022}
\item \textbf{Optimal Algorithms for Decentralized Stochastic Variational Inequalities} (\href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}, \href{https://anbeznosikov.github.io}{\color{linkcolour}Aleksandr Beznosikov}, \href{https://scholar.google.com/citations?user=R-xZRIAAAAAJ&hl=ru}{\color{linkcolour}Abdurakhmon Sadiev}, \href{}{\color{linkcolour}Michael Persiianov}, \href{https://richtarik.org}{\color{linkcolour}Peter Richtarik}, \href{https://scholar.google.ru/citations?user=AmeE8qkAAAAJ}{\color{linkcolour}Alexander Gasnikov}), \href{https://papers.nips.cc/paper_files/paper/2022/hash/c959bb2cb164d37569a17fa67494d69a-Abstract-Conference.html}{\em \color{black}NeurIPS 2022}
\item \textbf{Accelerated Primal-Dual Gradient Method for Smooth and Convex-Concave Saddle-Point Problems with Bilinear Coupling} (\href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}, \href{https://scholar.google.ru/citations?user=AmeE8qkAAAAJ}{\color{linkcolour}Alexander Gasnikov}, \href{https://richtarik.org}{\color{linkcolour}Peter Richtarik}), \href{https://papers.nips.cc/paper_files/paper/2022/hash/883f66687a521536c505f9b2fbdcbf1e-Abstract-Conference.html}{\em \color{black}NeurIPS 2022}
\item \textbf{Near-Optimal Decentralized Algorithms for Saddle Point Problems over Time-Varying Networks} (\href{https://anbeznosikov.github.io}{\color{linkcolour}Aleksandr Beznosikov}, \href{https://scholar.google.com/citations?user=sEjyzkgAAAAJ}{\color{linkcolour}Alexander Rogozin}, \href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}, \href{https://scholar.google.ru/citations?user=AmeE8qkAAAAJ}{\color{linkcolour}Alexander Gasnikov}), \href{https://link.springer.com/chapter/10.1007/978-3-030-91059-4_18}{\em \color{black}OPTIMA 2021}
\item \textbf{Lower Bounds and Optimal Algorithms for Smooth and Strongly Convex Decentralized Optimization Over Time-Varying Networks} (\href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}, \href{https://elnurgasanov.com}{\color{linkcolour}Elnur Gasanov}, \href{https://richtarik.org}{\color{linkcolour}Peter Richtarik}, \href{https://scholar.google.ru/citations?user=AmeE8qkAAAAJ}{\color{linkcolour}Alexander Gasnikov}), \href{https://proceedings.neurips.cc/paper/2021/hash/bc37e109d92bdc1ea71da6c919d54907-Abstract.html}{\em \color{black}NeurIPS 2021}
\item \textbf{An Optimal Algorithm for Strongly Convex Minimization under Affine Constraints} (\href{https://adil-salim.github.io}{\color{linkcolour}Adil Salim}, \href{https://lcondat.github.io}{\color{linkcolour}Laurent Condat}, \href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}, \href{https://richtarik.org}{\color{linkcolour}Peter Richtarik}), \href{http://aistats.org/aistats2022/accepted.html}{\em \color{black}AISTATS 2022}
\item \textbf{ADOM: Accelerated Decentralized Optimization Method for Time-Varying Networks} (\href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}, \href{https://shulgin-egor.github.io}{\color{linkcolour}Egor Shulgin}, \href{https://richtarik.org}{\color{linkcolour}Peter Richtarik}, \href{https://scholar.google.com/citations?user=sEjyzkgAAAAJ}{\color{linkcolour}Alexander Rogozin}, \href{https://scholar.google.ru/citations?user=AmeE8qkAAAAJ}{\color{linkcolour}Alexander Gasnikov}), \href{http://proceedings.mlr.press/v139/kovalev21a}{\em \color{black}ICML 2021}
\item \textbf{IntSGD: Floatless Compression of Stochastic Gradients} (\href{https://konstmish.github.io}{\color{linkcolour}Konstantin Mishchenko}, \href{https://bokunwang1.github.io}{\color{linkcolour}Bokun Wang}, \href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}, \href{https://richtarik.org}{\color{linkcolour}Peter Richtarik}), \href{https://openreview.net/forum?id=pFyXqxChZc}{\em \color{black}ICLR 2022}
\item \textbf{Accelerated Methods for Saddle-Point Problem} (\href{https://scholar.google.com/citations?user=dJgWojUAAAAJ}{\color{linkcolour}Mohammad Alkousa}, \href{https://scholar.google.com/citations?user=5ILnTRsAAAAJ}{\color{linkcolour}Darina Dvinskikh}, \href{https://scholar.google.ru/citations?user=AmeE8qkAAAAJ}{\color{linkcolour}Alexander Gasnikov}, \href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}, \href{https://www.researchgate.net/profile/Fedor_Stonyakin}{\color{linkcolour}Fedor Stonyakin}), \href{https://link.springer.com/article/10.1134/S0965542520110020}{\em \color{black}Computational Mathematics and Mathematical Physics}
\item \textbf{A Linearly Convergent Algorithm for Decentralized Optimization: Sending Less Bits for Free!} (\href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}, \href{https://scholar.google.com/citations?user=ldJpvE8AAAAJ}{\color{linkcolour}Anastasia Koloskova}, \href{https://people.epfl.ch/martin.jaggi}{\color{linkcolour}Martin Jaggi}, \href{https://richtarik.org}{\color{linkcolour}Peter Richtarik}, \href{https://sstich.ch}{\color{linkcolour}Sebastian U. Stich}), \href{http://proceedings.mlr.press/v130/kovalev21a}{\em \color{black}AISTATS 2021}
\item \textbf{Linearly Converging Error Compensated SGD} (\href{https://eduardgorbunov.github.io}{\color{linkcolour}Eduard Gorbunov}, \href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}, \href{}{\color{linkcolour}Dmitry Makarenko}, \href{https://richtarik.org}{\color{linkcolour}Peter Richtarik}), \href{https://papers.nips.cc/paper/2020/hash/ef9280fbc5317f17d480e4d4f61b3751-Abstract.html}{\em \color{black}NeurIPS 2020}
\item \textbf{Towards Accelerated Rates for Distributed Optimization over Time-varying Networks} (\href{https://scholar.google.com/citations?user=sEjyzkgAAAAJ}{\color{linkcolour}Alexander Rogozin}, \href{}{\color{linkcolour}Vladislav Lukoshkin}, \href{https://scholar.google.ru/citations?user=AmeE8qkAAAAJ}{\color{linkcolour}Alexander Gasnikov}, \href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}, \href{https://shulgin-egor.github.io}{\color{linkcolour}Egor Shulgin}), \href{https://link.springer.com/chapter/10.1007/978-3-030-91059-4_19}{\em \color{black}OPTIMA 2021}
\item \textbf{Optimal and Practical Algorithms for Smooth and Strongly Convex Decentralized Optimization} (\href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}, \href{https://adil-salim.github.io}{\color{linkcolour}Adil Salim}, \href{https://richtarik.org}{\color{linkcolour}Peter Richtarik}), \href{https://papers.nips.cc/paper/2020/hash/d530d454337fb09964237fecb4bea6ce-Abstract.html}{\em \color{black}NeurIPS 2020}
\item \textbf{From Local SGD to Local Fixed Point Methods for Federated Learning} (\href{https://scholar.google.com/citations?user=4w2W9KQAAAAJ}{\color{linkcolour}Grigory Malinovsky}, \href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}, \href{https://elnurgasanov.com}{\color{linkcolour}Elnur Gasanov}, \href{https://lcondat.github.io}{\color{linkcolour}Laurent Condat}, \href{https://richtarik.org}{\color{linkcolour}Peter Richtarik}), \href{http://proceedings.mlr.press/v119/malinovskiy20a.html}{\em \color{black}ICML 2020}
\item \textbf{Acceleration for Compressed Gradient Descent in Distributed and Federated Optimization} (\href{https://zhizeli.github.io}{\color{linkcolour}Zhize Li}, \href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}, \href{https://qianxunk.github.io}{\color{linkcolour}Xun Qian}, \href{https://richtarik.org}{\color{linkcolour}Peter Richtarik}), \href{http://proceedings.mlr.press/v119/li20g.html}{\em \color{black}ICML 2020}
\item \textbf{Variance Reduced Coordinate Descent with Acceleration: New Method With a Surprising Application to Finite-Sum Problems} (\href{https://fhanzely.github.io/index.html}{\color{linkcolour}Filip Hanzely}, \href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}, \href{https://richtarik.org}{\color{linkcolour}Peter Richtarik}), \href{http://proceedings.mlr.press/v119/hanzely20b.html}{\em \color{black}ICML 2020}
\item \textbf{Stochastic Newton and Cubic Newton Methods with Simple Local Linear-Quadratic Rates} (\href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}, \href{https://konstmish.github.io}{\color{linkcolour}Konstantin Mishchenko}, \href{https://richtarik.org}{\color{linkcolour}Peter Richtarik}), \href{https://sites.google.com/site/optneurips19/}{\em \color{black}NeurIPS 2019 Workshop}
\item \textbf{Stochastic Proximal Langevin Algorithm: Potential Splitting and Nonasymptotic Rates} (\href{https://adil-salim.github.io}{\color{linkcolour}Adil Salim}, \href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}, \href{https://richtarik.org}{\color{linkcolour}Peter Richtarik}), \href{https://papers.nips.cc/paper/8891-stochastic-proximal-langevin-algorithm-potential-splitting-and-nonasymptotic-rates}{\em \color{black}NeurIPS 2019}
\item \textbf{Revisiting Stochastic Extragradient} (\href{https://konstmish.github.io}{\color{linkcolour}Konstantin Mishchenko}, \href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}, \href{https://shulgin-egor.github.io}{\color{linkcolour}Egor Shulgin}, \href{https://richtarik.org}{\color{linkcolour}Peter Richtarik}, \href{https://scholar.google.com/citations?user=GI_-KjoAAAAJ}{\color{linkcolour}Yura Malitsky}), \href{http://proceedings.mlr.press/v108/mishchenko20a}{\em \color{black}AISTATS 2020}
\item \textbf{RSN: Randomized Subspace Newton} (\href{https://gowerrobert.github.io}{\color{linkcolour}Robert M. Gower}, \href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}, \href{http://www.opt.uni-duesseldorf.de/~lieder/de/inhalt.php}{\color{linkcolour}Felix Lieder}, \href{https://richtarik.org}{\color{linkcolour}Peter Richtarik}), \href{https://papers.nips.cc/paper/8351-rsn-randomized-subspace-newton}{\em \color{black}NeurIPS 2019}
\item \textbf{Stochastic Distributed Learning with Gradient Quantization and Double Variance Reduction} (\href{https://samuelhorvath.github.io}{\color{linkcolour}Samuel Horvath}, \href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}, \href{https://konstmish.github.io}{\color{linkcolour}Konstantin Mishchenko}, \href{https://richtarik.org}{\color{linkcolour}Peter Richtarik}, \href{https://sstich.ch}{\color{linkcolour}Sebastian U. Stich}), \href{https://www.tandfonline.com/doi/abs/10.1080/10556788.2022.2117355}{\em \color{black}Optimization Methods and Software}
\item \textbf{Don't Jump Through Hoops and Remove Those Loops: SVRG and Katyusha are Better Without the Outer Loop} (\href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}, \href{https://samuelhorvath.github.io}{\color{linkcolour}Samuel Horvath}, \href{https://richtarik.org}{\color{linkcolour}Peter Richtarik}), \href{http://proceedings.mlr.press/v117/kovalev20a}{\em \color{black}ALT 2020}
\item \textbf{A hypothesis about the rate of global convergence for optimal methods (Newton's type) in smooth convex optimization} (\href{https://scholar.google.ru/citations?user=AmeE8qkAAAAJ}{\color{linkcolour}Alexander Gasnikov}, \href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}), \href{http://crm-en.ics.org.ru/journal/article/2685/}{\em \color{black}Computer Research and Modeling}
\item \textbf{Stochastic Spectral and Conjugate Descent Methods} (\href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}, \href{https://eduardgorbunov.github.io}{\color{linkcolour}Eduard Gorbunov}, \href{https://elnurgasanov.com}{\color{linkcolour}Elnur Gasanov}, \href{https://richtarik.org}{\color{linkcolour}Peter Richtarik}), \href{https://papers.nips.cc/paper/7596-stochastic-spectral-and-conjugate-descent-methods}{\em \color{black}NeurIPS 2018}
\end{enumerate}
\section{Preprints}
\begin{enumerate}
\item \textbf{Decentralized Optimization over Time-varying Graphs: a Survey} (\href{https://scholar.google.com/citations?user=sEjyzkgAAAAJ}{\color{linkcolour}Alexander Rogozin}, \href{https://scholar.google.ru/citations?user=AmeE8qkAAAAJ}{\color{linkcolour}Alexander Gasnikov}, \href{}{\color{linkcolour}Aleksander Beznosikov}, \href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}), \href{https://arxiv.org/abs/2210.09719}{\em \color{black}arXiv preprint (October 2022)}
\item \textbf{Smooth Monotone Stochastic Variational Inequalities and Saddle Point Problems - Survey} (\href{https://anbeznosikov.github.io}{\color{linkcolour}Aleksandr Beznosikov}, \href{https://sites.google.com/site/lab7polyak/}{\color{linkcolour}Boris Polyak}, \href{https://eduardgorbunov.github.io}{\color{linkcolour}Eduard Gorbunov}, \href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}, \href{https://scholar.google.ru/citations?user=AmeE8qkAAAAJ}{\color{linkcolour}Alexander Gasnikov}), \href{https://arxiv.org/abs/2208.13592}{\em \color{black}arXiv preprint (August 2022)}
\item \textbf{On Scaled Methods for Saddle Point Problems} (\href{https://anbeznosikov.github.io}{\color{linkcolour}Aleksandr Beznosikov}, \href{}{\color{linkcolour}Aibek Alanov}, \href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}, \href{https://mtakac.com}{\color{linkcolour}Martin Takac}, \href{https://scholar.google.ru/citations?user=AmeE8qkAAAAJ}{\color{linkcolour}Alexander Gasnikov}), \href{https://arxiv.org/abs/2206.08303}{\em \color{black}arXiv preprint (June 2022)}
\item \textbf{Decentralized Saddle-Point Problems with Different Constants of Strong Convexity and Strong Concavity} (\href{}{\color{linkcolour}Dmitriy Metelev}, \href{https://scholar.google.com/citations?user=sEjyzkgAAAAJ}{\color{linkcolour}Alexander Rogozin}, \href{https://scholar.google.ru/citations?user=AmeE8qkAAAAJ}{\color{linkcolour}Alexander Gasnikov}, \href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}), \href{https://arxiv.org/abs/2206.00090}{\em \color{black}arXiv preprint (May 2022)}
\item \textbf{Decentralized Computation of Wasserstein Barycenter over Time-Varying Networks} (\href{https://scholar.google.com/citations?user=v6tuw7IAAAAJ}{\color{linkcolour}Olga Yufereva}, \href{}{\color{linkcolour}Michael Persiianov}, \href{http://wias-berlin.de/people/dvureche/}{\color{linkcolour}Pavel Dvurechensky}, \href{https://scholar.google.ru/citations?user=AmeE8qkAAAAJ}{\color{linkcolour}Alexander Gasnikov}, \href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}), \href{https://arxiv.org/abs/2205.15669}{\em \color{black}arXiv preprint (May 2022)}
\item \textbf{Decentralized Distributed Optimization for Saddle Point Problems} (\href{https://scholar.google.com/citations?user=sEjyzkgAAAAJ}{\color{linkcolour}Alexander Rogozin}, \href{https://anbeznosikov.github.io}{\color{linkcolour}Alexander Beznosikov}, \href{https://scholar.google.com/citations?user=5ILnTRsAAAAJ}{\color{linkcolour}Darina Dvinskikh}, \href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}, \href{http://wias-berlin.de/people/dvureche/}{\color{linkcolour}Pavel Dvurechensky}, \href{https://scholar.google.ru/citations?user=AmeE8qkAAAAJ}{\color{linkcolour}Alexander Gasnikov}), \href{https://arxiv.org/abs/2102.07758}{\em \color{black}arXiv preprint (February 2021)}
\item \textbf{Fast Linear Convergence of Randomized BFGS} (\href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}, \href{https://gowerrobert.github.io}{\color{linkcolour}Robert M. Gower}, \href{https://richtarik.org}{\color{linkcolour}Peter Richtarik}, \href{https://scholar.google.com/citations?user=sEjyzkgAAAAJ}{\color{linkcolour}Alexander Rogozin}), \href{https://arxiv.org/abs/2002.11337}{\em \color{black}arXiv preprint (February 2020)}
\item \textbf{Distributed Fixed Point Methods with Compressed Iterates} (\href{https://scholar.google.com/citations?user=gyiubRkAAAAJ}{\color{linkcolour}Selim Chraibi}, \href{https://rka97.github.io}{\color{linkcolour}Ahmed Khaled}, \href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}, \href{https://richtarik.org}{\color{linkcolour}Peter Richtarik}, \href{https://adil-salim.github.io}{\color{linkcolour}Adil Salim}, \href{https://mtakac.com}{\color{linkcolour}Martin Takac}), \href{https://arxiv.org/abs/1912.09925}{\em \color{black}arXiv preprint (December 2019)}
\item \textbf{Accelerated methods for composite non-bilinear saddle point problem} (\href{https://scholar.google.com/citations?user=dJgWojUAAAAJ}{\color{linkcolour}Mohammad Alkousa}, \href{https://scholar.google.com/citations?user=5ILnTRsAAAAJ}{\color{linkcolour}Darina Dvinskikh}, \href{https://www.researchgate.net/profile/Fedor_Stonyakin}{\color{linkcolour}Fedor Stonyakin}, \href{https://scholar.google.ru/citations?user=AmeE8qkAAAAJ}{\color{linkcolour}Alexander Gasnikov}, \href{https://www.dmitry-kovalev.com}{\color{linkcolour}Dmitry Kovalev}), \href{https://arxiv.org/abs/1906.03620}{\em \color{black}arXiv preprint (December 2019)}
\end{enumerate}
