title: Stochastic Spectral and Conjugate Descent Methods
abstract: The state-of-the-art methods for solving optimization problems in big dimensions are variants of randomized coordinate descent (RCD). In this paper we introduce a fundamentally new type of acceleration strategy for RCD based on the augmentation of the set of coordinate directions by a few spectral or conjugate directions. As we increase the number of extra directions to be sampled from, the rate of the method improves, and interpolates between the linear rate of RCD and a linear rate independent of the condition number. We develop and analyze also inexact variants of these methods where the spectral and conjugate directions are allowed to be approximate only. We motivate the above development by proving several negative results which highlight the limitations of RCD with importance sampling.
authors: Dmitry Kovalev
        Eduard Gorbunov
        Elnur Gasanov
        Peter Richt√°rik
date: 11 Feb 2018
links: {"PDF" : "https://arxiv.org/pdf/1802.03703.pdf", "NeurIPS 2018" : "https://papers.nips.cc/paper/7596-stochastic-spectral-and-conjugate-descent-methods", "arXiv" : "https://arxiv.org/abs/1802.03703"}