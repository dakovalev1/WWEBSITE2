@article{gasnikov2018hypothesis,
  title={A hypothesis about the rate of global convergence for optimal methods (Newton’s type) in smooth convex optimization},
  author={Gasnikov, Alexander Vladimirovich and Kovalev, Dmitry A and others},
  journal={Computer research and modeling},
  volume={10},
  number={3},
  pages={305--314},
  year={2018}
}

@inproceedings{kovalev2020don,
  title={Don’t jump through hoops and remove those loops: SVRG and Katyusha are better without the outer loop},
  author={Kovalev, Dmitry and Horv{\'a}th, Samuel and Richt{\'a}rik, Peter},
  booktitle={Algorithmic Learning Theory},
  pages={451--467},
  year={2020},
  organization={PMLR}
}

@article{kovalev2018stochastic,
  title={Stochastic spectral and conjugate descent methods},
  author={Kovalev, Dmitry and Richtarik, Peter and Gorbunov, Eduard and Gasanov, Elnur},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{gower2019rsn,
  title={RSN: randomized subspace Newton},
  author={Gower, Robert and Kovalev, Dmitry and Lieder, Felix and Richt{\'a}rik, Peter},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{salim2019stochastic,
  title={Stochastic proximal langevin algorithm: Potential splitting and nonasymptotic rates},
  author={Salim, Adil and Kovalev, Dmitry and Richt{\'a}rik, Peter},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{mishchenko2020revisiting,
  title={Revisiting stochastic extragradient},
  author={Mishchenko, Konstantin and Kovalev, Dmitry and Shulgin, Egor and Richt{\'a}rik, Peter and Malitsky, Yura},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4573--4582},
  year={2020},
  organization={PMLR}
}

@article{horvath2023stochastic,
  title={Stochastic distributed learning with gradient quantization and double-variance reduction},
  author={Horv{\'a}th, Samuel and Kovalev, Dmitry and Mishchenko, Konstantin and Richt{\'a}rik, Peter and Stich, Sebastian},
  journal={Optimization Methods and Software},
  volume={38},
  number={1},
  pages={91--106},
  year={2023},
  publisher={Taylor \& Francis}
}

@article{kovalev2019stochastic,
  title={Stochastic Newton and cubic Newton methods with simple local linear-quadratic rates},
  author={Kovalev, Dmitry and Mishchenko, Konstantin and Richt{\'a}rik, Peter},
  journal={arXiv preprint arXiv:1912.01597},
  year={2019}
}

@article{chraibi2019distributed,
  title={Distributed fixed point methods with compressed iterates},
  author={Chraibi, S{\'e}lim and Khaled, Ahmed and Kovalev, Dmitry and Richt{\'a}rik, Peter and Salim, Adil and Tak{\'a}{\v{c}}, Martin},
  journal={arXiv preprint arXiv:1912.09925},
  year={2019}
}

@article{alkousa2019accelerated,
  title={Accelerated methods for composite non-bilinear saddle point problem},
  author={Alkousa, Mohammad and Dvinskikh, Darina and Stonyakin, Fedor and Gasnikov, Alexander and Kovalev, Dmitry},
  journal={arXiv preprint arXiv:1906.03620},
  year={2019}
}

@inproceedings{hanzely2020variance,
  title={Variance reduced coordinate descent with acceleration: New method with a surprising application to finite-sum problems},
  author={Hanzely, Filip and Kovalev, Dmitry and Richtarik, Peter},
  booktitle={International Conference on Machine Learning},
  pages={4039--4048},
  year={2020},
  organization={PMLR}
}

@article{li2020acceleration,
  title={Acceleration for compressed gradient descent in distributed and federated optimization},
  author={Li, Zhize and Kovalev, Dmitry and Qian, Xun and Richt{\'a}rik, Peter},
  journal={arXiv preprint arXiv:2002.11364},
  year={2020}
}

@article{kovalev2020fast,
  title={Fast linear convergence of randomized BFGS},
  author={Kovalev, Dmitry and Gower, Robert M and Richt{\'a}rik, Peter and Rogozin, Alexander},
  journal={arXiv preprint arXiv:2002.11337},
  year={2020}
}

@inproceedings{malinovskiy2020local,
  title={From local SGD to local fixed-point methods for federated learning},
  author={Malinovskiy, Grigory and Kovalev, Dmitry and Gasanov, Elnur and Condat, Laurent and Richtarik, Peter},
  booktitle={International Conference on Machine Learning},
  pages={6692--6701},
  year={2020},
  organization={PMLR}
}

@article{kovalev2020optimal,
  title={Optimal and practical algorithms for smooth and strongly convex decentralized optimization},
  author={Kovalev, Dmitry and Salim, Adil and Richt{\'a}rik, Peter},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={18342--18352},
  year={2020}
}

@inproceedings{rogozin2021towards,
  title={Towards accelerated rates for distributed optimization over time-varying networks},
  author={Rogozin, Alexander and Lukoshkin, Vladislav and Gasnikov, Alexander and Kovalev, Dmitry and Shulgin, Egor},
  booktitle={Optimization and Applications: 12th International Conference, OPTIMA 2021, Petrovac, Montenegro, September 27--October 1, 2021, Proceedings 12},
  pages={258--272},
  year={2021},
  organization={Springer International Publishing}
}

@article{gorbunov2020linearly,
  title={Linearly converging error compensated SGD},
  author={Gorbunov, Eduard and Kovalev, Dmitry and Makarenko, Dmitry and Richt{\'a}rik, Peter},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={20889--20900},
  year={2020}
}

@inproceedings{kovalev2021linearly,
  title={A linearly convergent algorithm for decentralized optimization: Sending less bits for free!},
  author={Kovalev, Dmitry and Koloskova, Anastasia and Jaggi, Martin and Richtarik, Peter and Stich, Sebastian},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4087--4095},
  year={2021},
  organization={PMLR}
}

@article{alkousa2020accelerated,
  title={Accelerated methods for saddle-point problem},
  author={Alkousa, Mohammad S and Gasnikov, Alexander Vladimirovich and Dvinskikh, Darina Mikhailovna and Kovalev, Dmitry A and Stonyakin, Fedor Sergeevich},
  journal={Computational Mathematics and Mathematical Physics},
  volume={60},
  pages={1787--1809},
  year={2020},
  publisher={Pleiades Publishing}
}

@article{rogozin2021decentralized,
  title={Decentralized distributed optimization for saddle point problems},
  author={Rogozin, Alexander and Beznosikov, Aleksandr and Dvinskikh, Darina and Kovalev, Dmitry and Dvurechensky, Pavel and Gasnikov, Alexander},
  journal={arXiv preprint arXiv:2102.07758},
  year={2021}
}

@inproceedings{kovalev2021adom,
  title={ADOM: Accelerated decentralized optimization method for time-varying networks},
  author={Kovalev, Dmitry and Shulgin, Egor and Richt{\'a}rik, Peter and Rogozin, Alexander V and Gasnikov, Alexander},
  booktitle={International Conference on Machine Learning},
  pages={5784--5793},
  year={2021},
  organization={PMLR}
}

@inproceedings{salim2022optimal,
  title={An optimal algorithm for strongly convex minimization under affine constraints},
  author={Salim, Adil and Condat, Laurent and Kovalev, Dmitry and Richt{\'a}rik, Peter},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4482--4498},
  year={2022},
  organization={PMLR}
}

@article{kovalev2021lower,
  title={Lower bounds and optimal algorithms for smooth and strongly convex decentralized optimization over time-varying networks},
  author={Kovalev, Dmitry and Gasanov, Elnur and Gasnikov, Alexander and Richtarik, Peter},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={22325--22335},
  year={2021}
}

@inproceedings{beznosikov2021near,
  title={Near-optimal decentralized algorithms for saddle point problems over time-varying networks},
  author={Beznosikov, Aleksandr and Rogozin, Alexander and Kovalev, Dmitry and Gasnikov, Alexander},
  booktitle={Optimization and Applications: 12th International Conference, OPTIMA 2021, Petrovac, Montenegro, September 27--October 1, 2021, Proceedings 12},
  pages={246--257},
  year={2021},
  organization={Springer International Publishing}
}

@article{kovalev2022accelerated,
  title={Accelerated primal-dual gradient method for smooth and convex-concave saddle-point problems with bilinear coupling},
  author={Kovalev, Dmitry and Gasnikov, Alexander and Richt{\'a}rik, Peter},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={21725--21737},
  year={2022}
}

@article{tominin2021accelerated,
  title={On accelerated methods for saddle-point problems with composite structure},
  author={Tominin, Vladislav and Tominin, Yaroslav and Borodich, Ekaterina and Kovalev, Dmitry and Gasnikov, Alexander and Dvurechensky, Pavel},
  journal={arXiv preprint arXiv:2103.09344},
  year={2021}
}

@article{kovalev2022optimal1,
  title={Optimal algorithms for decentralized stochastic variational inequalities},
  author={Kovalev, Dmitry and Beznosikov, Aleksandr and Sadiev, Abdurakhmon and Persiianov, Michael and Richt{\'a}rik, Peter and Gasnikov, Alexander},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={31073--31088},
  year={2022}
}

@article{mishchenko2021intsgd,
  title={IntSGD: Adaptive floatless compression of stochastic gradients},
  author={Mishchenko, Konstantin and Wang, Bokun and Kovalev, Dmitry and Richt{\'a}rik, Peter},
  journal={arXiv preprint arXiv:2102.08374},
  year={2021}
}

@article{kovalev2022first1,
  title={The first optimal algorithm for smooth and strongly-convex-strongly-concave minimax optimization},
  author={Kovalev, Dmitry and Gasnikov, Alexander},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={14691--14703},
  year={2022}
}

@article{kovalev2022first2,
  title={The first optimal acceleration of high-order methods in smooth convex optimization},
  author={Kovalev, Dmitry and Gasnikov, Alexander},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={35339--35351},
  year={2022}
}


@article{kovalev2022optimal2,
  title={Optimal gradient sliding and its application to optimal distributed optimization under similarity},
  author={Kovalev, Dmitry and Beznosikov, Aleksandr and Borodich, Ekaterina and Gasnikov, Alexander and Scutari, Gesualdo},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={33494--33507},
  year={2022}
}

@article{metelev2024decentralized,
  title={Decentralized saddle-point problems with different constants of strong convexity and strong concavity},
  author={Metelev, Dmitry and Rogozin, Alexander and Gasnikov, Alexander and Kovalev, Dmitry},
  journal={Computational Management Science},
  volume={21},
  number={1},
  pages={5},
  year={2024},
  publisher={Springer Berlin Heidelberg Berlin/Heidelberg}
}

@article{beznosikov2022scaled,
  title={On scaled methods for saddle point problems},
  author={Beznosikov, Aleksandr and Alanov, Aibek and Kovalev, Dmitry and Tak{\'a}{\v{c}}, Martin and Gasnikov, Alexander},
  journal={arXiv preprint arXiv:2206.08303},
  year={2022}
}

@article{sadiev2022communication,
  title={Communication acceleration of local gradient methods via an accelerated primal-dual algorithm with an inexact prox},
  author={Sadiev, Abdurakhmon and Kovalev, Dmitry and Richt{\'a}rik, Peter},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={21777--21791},
  year={2022}
}

@article{beznosikov2023smooth,
  title={Smooth monotone stochastic variational inequalities and saddle point problems: A survey},
  author={Beznosikov, Aleksandr and Polyak, Boris and Gorbunov, Eduard and Kovalev, Dmitry and Gasnikov, Alexander},
  journal={European Mathematical Society Magazine},
  number={127},
  pages={15--28},
  year={2023}
}

@article{borodich2022accelerated,
  title={Accelerated variance-reduced methods for saddle-point problems},
  author={Borodich, Ekaterina and Tominin, Vladislav and Tominin, Yaroslav and Kovalev, Dmitry and Gasnikov, Alexander and Dvurechensky, Pavel},
  journal={EURO Journal on Computational Optimization},
  volume={10},
  pages={100048},
  year={2022},
  publisher={Elsevier}
}

@article{rogozin2022decentralized,
  title={Decentralized optimization over time-varying graphs: a survey},
  author={Rogozin, Alexander and Gasnikov, Alexander and Beznosikov, Aleksander and Kovalev, Dmitry},
  journal={arXiv preprint arXiv:2210.09719},
  year={2022}
}

@article{kovalev2022optimal3,
  title={An Optimal Algorithm for Strongly Convex Min-min Optimization},
  author={Kovalev, Dmitry and Gasnikov, Alexander and Malinovsky, Grigory},
  journal={arXiv preprint arXiv:2212.14439},
  year={2022}
}

@article{yufereva2022decentralized,
  title={Decentralized Convex Optimization on Time-Varying Networks with Application to Wasserstein Barycenters},
  author={Yufereva, Olga and Persiianov, Michael and Dvurechensky, Pavel and Gasnikov, Alexander and Kovalev, Dmitry},
  journal={arXiv preprint arXiv:2205.15669},
  year={2022}
}

@article{beznosikov2021optimal,
  title={Optimal Decentralized Algorithms for Saddle Point Problems over Time-Varying Networks},
  author={Beznosikov, Aleksandr and Rogozin, Alexander and Kovalev, Dmitry and Gasnikov, Alexander},
  year={2021},
  publisher={arXiv}
}

@inproceedings{metelev2023consensus,
  title={Is consensus acceleration possible in decentralized optimization over slowly time-varying networks?},
  author={Metelev, Dmitry and Rogozin, Alexander and Kovalev, Dmitry and Gasnikov, Alexander},
  booktitle={International Conference on Machine Learning},
  pages={24532--24554},
  year={2023},
  organization={PMLR}
}


@article{lobanov2023non,
  title={Non-smooth setting of stochastic decentralized convex optimization problem over time-varying graphs},
  author={Lobanov, Aleksandr and Veprikov, Andrew and Konin, Georgiy and Beznosikov, Aleksandr and Gasnikov, Alexander and Kovalev, Dmitry},
  journal={Computational Management Science},
  volume={20},
  number={1},
  pages={48},
  year={2023},
  publisher={Springer Berlin Heidelberg Berlin/Heidelberg}
}

@article{borodich2023optimal,
  title={Optimal Algorithm with Complexity Separation for Strongly Convex-Strongly Concave Composite Saddle Point Problems},
  author={Borodich, Ekaterina and Kormakov, Georgiy and Kovalev, Dmitry and Beznosikov, Aleksandr and Gasnikov, Alexander},
  journal={arXiv preprint arXiv:2307.12946},
  year={2023}
}
