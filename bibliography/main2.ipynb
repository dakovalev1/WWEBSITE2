{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scholarly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "pg = scholarly.ProxyGenerator()\n",
    "success = pg.FreeProxies()\n",
    "print(success)\n",
    "scholarly.scholarly.use_proxy(pg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'container_type': 'Publication',\n",
       " 'source': <PublicationSource.PUBLICATION_SEARCH_SNIPPET: 'PUBLICATION_SEARCH_SNIPPET'>,\n",
       " 'bib': {'title': 'Acceleration for compressed gradient descent in distributed and federated optimization',\n",
       "  'author': \"Li, Zhize and Kovalev, Dmitry and Qian, Xun and Richt{\\\\'a}rik, Peter\",\n",
       "  'pub_year': '2020',\n",
       "  'venue': 'arXiv preprint arXiv:2002.11364',\n",
       "  'abstract': 'Due to the high communication cost in distributed and federated learning problems, methods relying on compression of communicated messages are becoming increasingly popular. While in other contexts the best performing gradient-type methods invariably rely on some form of acceleration/momentum to reduce the number of iterations, there are no methods which combine the benefits of both gradient compression and acceleration. In this paper, we remedy this situation and propose the first accelerated compressed gradient',\n",
       "  'journal': 'arXiv preprint arXiv:2002.11364',\n",
       "  'pub_type': 'article',\n",
       "  'bib_id': 'li2020acceleration'},\n",
       " 'filled': True,\n",
       " 'gsrank': 1,\n",
       " 'pub_url': 'https://arxiv.org/abs/2002.11364',\n",
       " 'author_id': ['uAFPPigAAAAJ', 'qHFA5z4AAAAJ', '2QtdkysAAAAJ', 'pGh242UAAAAJ'],\n",
       " 'url_scholarbib': '/scholar?hl=en&q=info:lgohCMY3CRMJ:scholar.google.com/&output=cite&scirp=0&hl=en',\n",
       " 'url_add_sclib': '/citations?hl=en&xsrf=&continue=/scholar%3Fq%3DAcceleration%2Bfor%2Bcompressed%2Bgradient%2Bdescent%2Bin%2Bdistributed%2Band%2Bfederated%2Boptimization%26hl%3Den%26as_sdt%3D0,5&citilm=1&update_op=library_add&info=lgohCMY3CRMJ&ei=hVW2Zu3LMrSp6rQP5pGgcQ&json=',\n",
       " 'num_citations': 155,\n",
       " 'citedby_url': '/scholar?cites=1371688885190462102&as_sdt=2005&sciodt=0,5&hl=en',\n",
       " 'url_related_articles': '/scholar?q=related:lgohCMY3CRMJ:scholar.google.com/&scioq=Acceleration+for+compressed+gradient+descent+in+distributed+and+federated+optimization&hl=en&as_sdt=0,5',\n",
       " 'eprint_url': 'https://arxiv.org/pdf/2002.11364'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub = scholarly.scholarly.search_single_pub(\n",
    "    \"Acceleration for compressed gradient descent in distributed and federated optimization\",\n",
    "    True,\n",
    ")\n",
    "pub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = scholarly.scholarly.search_pubs(\n",
    "    \"Perception of physical stability and center of mass of 3D objects\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
