{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import typing\n",
    "import bs4\n",
    "import pickle\n",
    "\n",
    "PROXY_URL = \"http://5zipXAuZVPsquwtL:wifi;;;;@proxy.froxy.com:9000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url = https://scholar.google.com/citations?hl=en&user=qHFA5z4AAAAJ&pagesize=100 status = 200\n"
     ]
    }
   ],
   "source": [
    "def get(url: str) -> str:\n",
    "    with requests.request(\n",
    "        method=\"GET\",\n",
    "        url=url,\n",
    "        headers={\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36\",\n",
    "        },\n",
    "        proxies={\"https\": PROXY_URL, \"http\": PROXY_URL},\n",
    "    ) as response:\n",
    "\n",
    "        print(\"url =\", url, \"status =\", response.status_code)\n",
    "        return response.text\n",
    "\n",
    "\n",
    "html = get(\"https://scholar.google.com/citations?hl=en&user=qHFA5z4AAAAJ&pagesize=100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:Y0pCki6q_DkC title = Stochastic distributed learning with gradient quantization and double-variance reduction\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:2osOgNQ5qMEC title = Donâ€™t jump through hoops and remove those loops: SVRG and Katyusha are better without the outer loop\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:bnK-pcrLprsC title = Acceleration for compressed gradient descent in distributed and federated optimization\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:Se3iqnhoufwC title = From local SGD to local fixed-point methods for federated learning\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:IjCSPb-OGe4C title = RSN: randomized subspace Newton\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:8k81kl-MbHgC title = Linearly converging error compensated SGD\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:Tyk-4Ss8FVUC title = Revisiting stochastic extragradient\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:UebtZRa9Y70C title = Optimal and practical algorithms for smooth and strongly convex decentralized optimization\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:MXK_kJrjxJIC title = A linearly convergent algorithm for decentralized optimization: Sending less bits for free!\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:kNdYIx-mwKoC title = Accelerated methods for saddle-point problem\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:YsMSGLbcyi4C title = Stochastic Newton and cubic Newton methods with simple local linear-quadratic rates\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:KlAtU1dfN6UC title = Decentralized distributed optimization for saddle point problems\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:9ZlFYXVOiuMC title = Lower bounds and optimal algorithms for smooth and strongly convex decentralized optimization over time-varying networks\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:RHpTSmoSYBkC title = Accelerated primal-dual gradient method for smooth and convex-concave saddle-point problems with bilinear coupling\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:ULOm3_A8WrAC title = ADOM: accelerated decentralized optimization method for time-varying networks\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:TFP_iSt0sucC title = Optimal algorithms for decentralized stochastic variational inequalities\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:iH-uZ7U-co4C title = On accelerated methods for saddle-point problems with composite structure\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:GnPB-g6toBAC title = The first optimal acceleration of high-order methods in smooth convex optimization\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:0EnyYjriUFMC title = Towards accelerated rates for distributed optimization over time-varying networks\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:zYLM7Y9cAGgC title = Stochastic proximal langevin algorithm: Potential splitting and nonasymptotic rates\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:nb7KW1ujOQ8C title = IntSGD: Adaptive floatless compression of stochastic gradients\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:4TOpqqG69KYC title = An optimal algorithm for strongly convex minimization under affine constraints\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:eQOLeE2rZwMC title = Distributed fixed point methods with compressed iterates\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:ldfaerwXgEUC title = Smooth monotone stochastic variational inequalities and saddle point problems: A survey\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:RGFaLdJalmkC title = Optimal gradient sliding and its application to optimal distributed optimization under similarity\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:BqipwSGYUEgC title = The first optimal algorithm for smooth and strongly-convex-strongly-concave minimax optimization\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:ufrVoPGSRksC title = Variance reduced coordinate descent with acceleration: New method with a surprising application to finite-sum problems\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:LkGwnXOMwfcC title = Fast linear convergence of randomized BFGS\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:7PzlFSSx8tAC title = Near-optimal decentralized algorithms for saddle point problems over time-varying networks\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:qjMakFHDy7sC title = Stochastic spectral and conjugate descent methods\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:35N4QoGY0k4C title = Communication acceleration of local gradient methods via an accelerated primal-dual algorithm with an inexact prox\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:NaGl4SEjCO4C title = Decentralized saddle-point problems with different constants of strong convexity and strong concavity\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:ZHo1McVdvXMC title = Decentralized optimization over time-varying graphs: a survey\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:pyW8ca7W8N0C title = Is consensus acceleration possible in decentralized optimization over slowly time-varying networks?\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:J_g5lzvAfSwC title = On scaled methods for saddle point problems\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:yD5IFk8b50cC title = Decentralized convex optimization on time-varying networks with application to Wasserstein barycenters\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:_xSYboBqXhAC title = Non-smooth setting of stochastic decentralized convex optimization problem over time-varying graphs\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:d1gkVwhDpl0C title = A hypothesis about the rate of global convergence for optimal methods (Newtonâ€™s type) in smooth convex optimization\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:4OULZ7Gr8RgC title = An optimal algorithm for strongly convex min-min optimization\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:p2g8aNsByqUC title = Decentralized saddle point problems via non-Euclidean mirror prox\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:Tiz5es2fbqcC title = Decentralized Finite-Sum Optimization over Time-Varying Networks\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:EUQCXRtRnyEC title = Optimal algorithm with complexity separation for strongly convex-strongly concave composite saddle point problems\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:HoB7MX3m0LUC title = Accelerated variance-reduced methods for saddle-point problems\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:V3AGJWp-ZtQC title = Decentralized Optimization with Coupled Constraints\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:geHnlv5EZngC title = Lower Bounds and Optimal Algorithms for Non-Smooth Convex Decentralized Optimization over Time-Varying Networks\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:dshw04ExmUIC title = Decentralized Convex Optimization over Time-Varying Graphs\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:olpn-zPbct0C title = Decentralized convex optimization over time-varying graphs: a survey\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:pqnbT2bcN3wC title = Optimal Algorithms for Affinely Constrained, Distributed, Decentralized, Minimax, and High-Order Optimization Problems\n"
     ]
    }
   ],
   "source": [
    "soup = bs4.BeautifulSoup(html)\n",
    "paper_list: bs4.ResultSet[bs4.Tag] = soup.find_all(\n",
    "    name=\"tr\", attrs={\"class\": \"gsc_a_tr\"}\n",
    ")\n",
    "\n",
    "print(len(paper_list))\n",
    "for paper in paper_list:\n",
    "    paper_link = paper.find(name=\"a\", attrs={\"class\": \"gsc_a_at\"})\n",
    "    print(\n",
    "        \"url =\",\n",
    "        \"https://scholar.google.com\" + paper_link.attrs[\"href\"],\n",
    "        \"title =\",\n",
    "        paper_link.text,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paper_soup2dict(paper_html: str) -> typing.Dict[str, bs4.Tag]:\n",
    "    paper_soup = bs4.BeautifulSoup(paper_html)\n",
    "    key_list: bs4.ResultSet[bs4.Tag] = paper_soup.find_all(\n",
    "        name=\"div\", attrs={\"class\": \"gsc_oci_field\"}\n",
    "    )\n",
    "    value_list: bs4.ResultSet[bs4.Tag] = paper_soup.find_all(\n",
    "        name=\"div\", attrs={\"class\": \"gsc_oci_value\"}\n",
    "    )\n",
    "    paper_dict: typing.Dict[str, bs4.Tag] = {}\n",
    "    for key, value in zip(key_list, value_list):\n",
    "        paper_dict[key.text] = value\n",
    "    return paper_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:Y0pCki6q_DkC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:2osOgNQ5qMEC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:bnK-pcrLprsC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:Se3iqnhoufwC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:IjCSPb-OGe4C status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:8k81kl-MbHgC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:Tyk-4Ss8FVUC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:UebtZRa9Y70C status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:MXK_kJrjxJIC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:kNdYIx-mwKoC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:YsMSGLbcyi4C status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:KlAtU1dfN6UC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:9ZlFYXVOiuMC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:RHpTSmoSYBkC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:ULOm3_A8WrAC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:TFP_iSt0sucC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:iH-uZ7U-co4C status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:GnPB-g6toBAC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:0EnyYjriUFMC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:zYLM7Y9cAGgC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:nb7KW1ujOQ8C status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:4TOpqqG69KYC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:eQOLeE2rZwMC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:ldfaerwXgEUC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:RGFaLdJalmkC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:BqipwSGYUEgC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:ufrVoPGSRksC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:LkGwnXOMwfcC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:7PzlFSSx8tAC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:qjMakFHDy7sC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:35N4QoGY0k4C status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:NaGl4SEjCO4C status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:ZHo1McVdvXMC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:pyW8ca7W8N0C status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:J_g5lzvAfSwC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:yD5IFk8b50cC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:_xSYboBqXhAC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:d1gkVwhDpl0C status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:4OULZ7Gr8RgC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:p2g8aNsByqUC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:Tiz5es2fbqcC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:EUQCXRtRnyEC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:HoB7MX3m0LUC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:V3AGJWp-ZtQC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:geHnlv5EZngC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:dshw04ExmUIC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:olpn-zPbct0C status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:pqnbT2bcN3wC status = 200\n"
     ]
    }
   ],
   "source": [
    "paper_dict_list: typing.List[typing.Dict[str, bs4.Tag]] = []\n",
    "for paper in paper_list:\n",
    "    paper_url = (\n",
    "        \"https://scholar.google.com\"\n",
    "        + paper.find(name=\"a\", attrs={\"class\": \"gsc_a_at\"}).attrs[\"href\"]\n",
    "    )\n",
    "    paper_html = get(paper_url)\n",
    "    paper_dict = paper_soup2dict(paper_html)\n",
    "    paper_dict_list.append(paper_dict)\n",
    "pickle.dump(paper_dict_list, open(\"dump.txt\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Authors': <div class=\"gsc_oci_value\">Samuel HorvÃ¡th, Dmitry Kovalev, Konstantin Mishchenko, Peter RichtÃ¡rik, Sebastian Stich</div>,\n",
       " 'Publication date': <div class=\"gsc_oci_value\">2023/1/2</div>,\n",
       " 'Journal': <div class=\"gsc_oci_value\">Optimization Methods and Software</div>,\n",
       " 'Volume': <div class=\"gsc_oci_value\">38</div>,\n",
       " 'Issue': <div class=\"gsc_oci_value\">1</div>,\n",
       " 'Pages': <div class=\"gsc_oci_value\">91-106</div>,\n",
       " 'Publisher': <div class=\"gsc_oci_value\">Taylor &amp; Francis</div>,\n",
       " 'Description': <div class=\"gsc_oci_value\" id=\"gsc_oci_descr\"><div class=\"gsh_small\"><div class=\"gsh_csp\">We consider distributed optimization over several devices, each sending incremental model updates to a central server. This setting is considered, for instance, in federated learning. Various schemes have been designed to compress the model updates in order to reduce the overall communication cost. However, existing methods suffer from a significant slowdown due to additional variance <svg aria-label=\"Ï‰&gt;0\" class=\"gs_fsvg\" height=\"10px\" style=\"vertical-align:-1px;\" width=\"35px\"><g transform=\"matrix(0.01400, 0.00000, 0.00000, 0.01400, 0.00000, 9.32400)\"><g><path d=\"M 248 -23  Q 132 -23 80 62  T 29 270  Q 29 351 43 428  T 87 585  T 155 734  T 240 870  Q 249 883 264 883  Q 277 883 285 875  T 293 856  Q 293 845 287 836  Q 100 579 100 362  Q 100 268 143 200  T 276 133  Q 353 133 418 178  T 532 293  Q 532 329 544 405  T 583 540  T 647 600  Q 694 600 694 545  Q 694 513 680 464  T 650 374  T 610 279  Q 634 133 756 133  Q 827 133 898 174  T 1025 281  T 1111 425  T 1143 571  Q 1143 633 1123 667  T 1072 740  T 1040 801  Q 1040 841 1074 874  T 1147 907  Q 1197 907 1218 861  T 1239 758  Q 1239 664 1201 521  T 1116 283  Q 1050 154 950 65  T 727 -23  Q 648 -23 599 24  T 537 154  Q 480 73 407 25  T 248 -23  Z \" transform=\"scale(0.48828, -0.48828)\"></path><g transform=\"translate(658.31903, 0.00000)\"><path d=\"M 170 -41  Q 170 -15 197 -2  L 1284 512  L 190 1030  Q 170 1036 170 1065  Q 170 1079 181 1092  T 211 1106  Q 215 1106 227 1102  L 1403 547  Q 1421 538 1421 512  Q 1421 485 1397 475  L 227 -78  Q 215 -82 211 -82  Q 193 -82 181 -69  T 170 -41  Z \" transform=\"matrix(0.48828, 0.00000, 0.00000, -0.48828, 277.77780, 0.00000)\"></path></g><path d=\"M 512 -45  Q 261 -45 170 161  T 80 653  Q 80 831 112 988  T 241 1254  T 512 1364  Q 647 1364 733 1298  T 864 1127  T 925 903  T 942 653  Q 942 477 909 323  T 782 62  T 512 -45  Z M 512 8  Q 626 8 682 125  T 751 384  T 764 686  Q 764 840 751 970  T 682 1205  T 512 1311  Q 396 1311 340 1205  T 271 969  T 258 686  Q 258 572 263 471  T 293 262  T 370 81  T 512 8  Z \" transform=\"matrix(0.48828, 0.00000, 0.00000, -0.48828, 1991.65479, 0.00000)\"></path></g></g></svg> coming from the compression operator and as a result, only converge sublinearly. What is needed is a variance reduction technique for taming the variance introduced by compression. We propose the first methods that achieve linear convergence for arbitrary compression operators. For strongly convex functions with condition number <i>Îº</i>, distributed among <i>n</i> machines with a finite-sum structure, each worker having less than <i>m</i> components, we also (i)Â give analysis for the weakly convex and the non-convex cases and (iiÂ â€¦</div></div></div>,\n",
       " 'Total citations': <div class=\"gsc_oci_value\"><div style=\"margin-bottom:1em\"><a href=\"https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10432066948921138844&amp;as_sdt=5\">Cited by 180</a></div><div id=\"gsc_oci_graph_wrapper\"><div id=\"gsc_oci_graph\" style=\"width:196px;\"><div id=\"gsc_oci_graph_x\"></div><div id=\"gsc_oci_graph_bars\"><span class=\"gsc_oci_g_t\" style=\"left:0px\">2019</span><span class=\"gsc_oci_g_t\" style=\"left:33px\">2020</span><span class=\"gsc_oci_g_t\" style=\"left:66px\">2021</span><span class=\"gsc_oci_g_t\" style=\"left:99px\">2022</span><span class=\"gsc_oci_g_t\" style=\"left:132px\">2023</span><span class=\"gsc_oci_g_t\" style=\"left:165px\">2024</span><a class=\"gsc_oci_g_a\" href=\"https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10432066948921138844&amp;as_sdt=5&amp;as_ylo=2019&amp;as_yhi=2019\" style=\"left:5px;height:10px;top:47px;z-index:6\"><span class=\"gsc_oci_g_al\">8</span></a><a class=\"gsc_oci_g_a\" href=\"https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10432066948921138844&amp;as_sdt=5&amp;as_ylo=2020&amp;as_yhi=2020\" style=\"left:38px;height:33px;top:24px;z-index:5\"><span class=\"gsc_oci_g_al\">26</span></a><a class=\"gsc_oci_g_a\" href=\"https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10432066948921138844&amp;as_sdt=5&amp;as_ylo=2021&amp;as_yhi=2021\" style=\"left:71px;height:56px;top:1px;z-index:4\"><span class=\"gsc_oci_g_al\">44</span></a><a class=\"gsc_oci_g_a\" href=\"https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10432066948921138844&amp;as_sdt=5&amp;as_ylo=2022&amp;as_yhi=2022\" style=\"left:104px;height:57px;top:0px;z-index:3\"><span class=\"gsc_oci_g_al\">45</span></a><a class=\"gsc_oci_g_a\" href=\"https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10432066948921138844&amp;as_sdt=5&amp;as_ylo=2023&amp;as_yhi=2023\" style=\"left:137px;height:42px;top:15px;z-index:2\"><span class=\"gsc_oci_g_al\">33</span></a><a class=\"gsc_oci_g_a\" href=\"https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10432066948921138844&amp;as_sdt=5&amp;as_ylo=2024&amp;as_yhi=2024\" style=\"left:170px;height:29px;top:28px;z-index:1\"><span class=\"gsc_oci_g_al\">23</span></a></div></div></div></div>,\n",
       " 'Scholar articles': <div class=\"gsc_oci_value\"><div class=\"gsc_oci_merged_snippet\"><div><a href=\"/scholar?oi=bibs&amp;cluster=10432066948921138844&amp;btnI=1&amp;hl=en\">Stochastic distributed learning with gradient quantization and double-variance reduction</a></div><div>S HorvÃ¡th, D Kovalev, K Mishchenko, P RichtÃ¡rikâ€¦Â - Optimization Methods and Software, 2023</div><div><a class=\"gsc_oms_link\" href=\"https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10432066948921138844&amp;as_sdt=5\">Cited by 180</a> <a class=\"gsc_oms_link\" href=\"https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;q=related:nJ6JW54lxpAJ:scholar.google.com/\">Related articles</a> <a class=\"gsc_oms_link\" href=\"https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cluster=10432066948921138844\">All 17 versions</a> </div></div></div>}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_dict_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
