{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import typing\n",
    "import bs4\n",
    "import pickle\n",
    "import urllib.parse\n",
    "\n",
    "PROXY_URL = \"http://5zipXAuZVPsquwtL:wifi;;;;@proxy.froxy.com:9000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get(url: str) -> str:\n",
    "    with requests.request(\n",
    "        method=\"GET\",\n",
    "        url=url,\n",
    "        headers={\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36\",\n",
    "        },\n",
    "        proxies={\"https\": PROXY_URL, \"http\": PROXY_URL},\n",
    "    ) as response:\n",
    "\n",
    "        print(\"url =\", url, \"status =\", response.status_code)\n",
    "        return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url = https://scholar.google.com/citations?hl=en&user=qHFA5z4AAAAJ&pagesize=100 status = 200\n",
      "48\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:Y0pCki6q_DkC title = Stochastic distributed learning with gradient quantization and double-variance reduction\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:2osOgNQ5qMEC title = Donâ€™t jump through hoops and remove those loops: SVRG and Katyusha are better without the outer loop\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:bnK-pcrLprsC title = Acceleration for compressed gradient descent in distributed and federated optimization\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:Se3iqnhoufwC title = From local SGD to local fixed-point methods for federated learning\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:IjCSPb-OGe4C title = RSN: randomized subspace Newton\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:8k81kl-MbHgC title = Linearly converging error compensated SGD\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:Tyk-4Ss8FVUC title = Revisiting stochastic extragradient\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:UebtZRa9Y70C title = Optimal and practical algorithms for smooth and strongly convex decentralized optimization\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:MXK_kJrjxJIC title = A linearly convergent algorithm for decentralized optimization: Sending less bits for free!\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:kNdYIx-mwKoC title = Accelerated methods for saddle-point problem\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:YsMSGLbcyi4C title = Stochastic Newton and cubic Newton methods with simple local linear-quadratic rates\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:KlAtU1dfN6UC title = Decentralized distributed optimization for saddle point problems\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:9ZlFYXVOiuMC title = Lower bounds and optimal algorithms for smooth and strongly convex decentralized optimization over time-varying networks\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:RHpTSmoSYBkC title = Accelerated primal-dual gradient method for smooth and convex-concave saddle-point problems with bilinear coupling\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:ULOm3_A8WrAC title = ADOM: accelerated decentralized optimization method for time-varying networks\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:TFP_iSt0sucC title = Optimal algorithms for decentralized stochastic variational inequalities\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:iH-uZ7U-co4C title = On accelerated methods for saddle-point problems with composite structure\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:GnPB-g6toBAC title = The first optimal acceleration of high-order methods in smooth convex optimization\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:0EnyYjriUFMC title = Towards accelerated rates for distributed optimization over time-varying networks\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:zYLM7Y9cAGgC title = Stochastic proximal langevin algorithm: Potential splitting and nonasymptotic rates\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:nb7KW1ujOQ8C title = IntSGD: Adaptive floatless compression of stochastic gradients\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:4TOpqqG69KYC title = An optimal algorithm for strongly convex minimization under affine constraints\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:eQOLeE2rZwMC title = Distributed fixed point methods with compressed iterates\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:ldfaerwXgEUC title = Smooth monotone stochastic variational inequalities and saddle point problems: A survey\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:RGFaLdJalmkC title = Optimal gradient sliding and its application to optimal distributed optimization under similarity\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:BqipwSGYUEgC title = The first optimal algorithm for smooth and strongly-convex-strongly-concave minimax optimization\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:ufrVoPGSRksC title = Variance reduced coordinate descent with acceleration: New method with a surprising application to finite-sum problems\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:LkGwnXOMwfcC title = Fast linear convergence of randomized BFGS\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:7PzlFSSx8tAC title = Near-optimal decentralized algorithms for saddle point problems over time-varying networks\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:qjMakFHDy7sC title = Stochastic spectral and conjugate descent methods\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:35N4QoGY0k4C title = Communication acceleration of local gradient methods via an accelerated primal-dual algorithm with an inexact prox\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:NaGl4SEjCO4C title = Decentralized saddle-point problems with different constants of strong convexity and strong concavity\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:ZHo1McVdvXMC title = Decentralized optimization over time-varying graphs: a survey\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:pyW8ca7W8N0C title = Is consensus acceleration possible in decentralized optimization over slowly time-varying networks?\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:J_g5lzvAfSwC title = On scaled methods for saddle point problems\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:yD5IFk8b50cC title = Decentralized convex optimization on time-varying networks with application to Wasserstein barycenters\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:_xSYboBqXhAC title = Non-smooth setting of stochastic decentralized convex optimization problem over time-varying graphs\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:d1gkVwhDpl0C title = A hypothesis about the rate of global convergence for optimal methods (Newtonâ€™s type) in smooth convex optimization\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:4OULZ7Gr8RgC title = An optimal algorithm for strongly convex min-min optimization\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:p2g8aNsByqUC title = Decentralized saddle point problems via non-Euclidean mirror prox\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:Tiz5es2fbqcC title = Decentralized Finite-Sum Optimization over Time-Varying Networks\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:EUQCXRtRnyEC title = Optimal algorithm with complexity separation for strongly convex-strongly concave composite saddle point problems\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:HoB7MX3m0LUC title = Accelerated variance-reduced methods for saddle-point problems\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:V3AGJWp-ZtQC title = Decentralized Optimization with Coupled Constraints\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:geHnlv5EZngC title = Lower Bounds and Optimal Algorithms for Non-Smooth Convex Decentralized Optimization over Time-Varying Networks\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:dshw04ExmUIC title = Decentralized Convex Optimization over Time-Varying Graphs\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:olpn-zPbct0C title = Decentralized convex optimization over time-varying graphs: a survey\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:pqnbT2bcN3wC title = Optimal Algorithms for Affinely Constrained, Distributed, Decentralized, Minimax, and High-Order Optimization Problems\n"
     ]
    }
   ],
   "source": [
    "html = get(\"https://scholar.google.com/citations?hl=en&user=qHFA5z4AAAAJ&pagesize=100\")\n",
    "soup = bs4.BeautifulSoup(html)\n",
    "paper_list: bs4.ResultSet[bs4.Tag] = soup.find_all(\n",
    "    name=\"tr\", attrs={\"class\": \"gsc_a_tr\"}\n",
    ")\n",
    "\n",
    "print(len(paper_list))\n",
    "for paper in paper_list:\n",
    "    paper_link = paper.find(name=\"a\", attrs={\"class\": \"gsc_a_at\"})\n",
    "    print(\n",
    "        \"url =\",\n",
    "        \"https://scholar.google.com\" + paper_link.attrs[\"href\"],\n",
    "        \"title =\",\n",
    "        paper_link.text,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get paper cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paper_soup2dict(paper_html: str) -> typing.Dict[str, bs4.Tag]:\n",
    "    paper_soup = bs4.BeautifulSoup(paper_html)\n",
    "\n",
    "    key_list: bs4.ResultSet[bs4.Tag] = paper_soup.find_all(\n",
    "        name=\"div\", attrs={\"class\": \"gsc_oci_field\"}\n",
    "    )\n",
    "    value_list: bs4.ResultSet[bs4.Tag] = paper_soup.find_all(\n",
    "        name=\"div\", attrs={\"class\": \"gsc_oci_value\"}\n",
    "    )\n",
    "\n",
    "    paper_dict: typing.Dict[str, bs4.Tag] = {}\n",
    "    paper_dict[\"Title\"] = paper_soup.find(\n",
    "        name=\"a\", attrs={\"class\": \"gsc_oci_title_link\"}\n",
    "    )\n",
    "    for key, value in zip(key_list, value_list):\n",
    "        paper_dict[key.text] = value\n",
    "\n",
    "    return paper_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:Y0pCki6q_DkC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:2osOgNQ5qMEC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:bnK-pcrLprsC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:Se3iqnhoufwC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:IjCSPb-OGe4C status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:8k81kl-MbHgC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:Tyk-4Ss8FVUC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:UebtZRa9Y70C status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:MXK_kJrjxJIC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:kNdYIx-mwKoC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:YsMSGLbcyi4C status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:KlAtU1dfN6UC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:9ZlFYXVOiuMC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:RHpTSmoSYBkC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:ULOm3_A8WrAC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:TFP_iSt0sucC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:iH-uZ7U-co4C status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:GnPB-g6toBAC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:0EnyYjriUFMC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:zYLM7Y9cAGgC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:nb7KW1ujOQ8C status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:4TOpqqG69KYC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:eQOLeE2rZwMC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:ldfaerwXgEUC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:RGFaLdJalmkC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:BqipwSGYUEgC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:ufrVoPGSRksC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:LkGwnXOMwfcC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:7PzlFSSx8tAC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:qjMakFHDy7sC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:35N4QoGY0k4C status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:NaGl4SEjCO4C status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:ZHo1McVdvXMC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:pyW8ca7W8N0C status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:J_g5lzvAfSwC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:yD5IFk8b50cC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:_xSYboBqXhAC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:d1gkVwhDpl0C status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:4OULZ7Gr8RgC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:p2g8aNsByqUC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:Tiz5es2fbqcC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:EUQCXRtRnyEC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:HoB7MX3m0LUC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:V3AGJWp-ZtQC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:geHnlv5EZngC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:dshw04ExmUIC status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:olpn-zPbct0C status = 200\n",
      "url = https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qHFA5z4AAAAJ&pagesize=100&citation_for_view=qHFA5z4AAAAJ:pqnbT2bcN3wC status = 200\n"
     ]
    }
   ],
   "source": [
    "paper_dict_list: typing.List[typing.Dict[str, bs4.Tag]] = []\n",
    "for paper in paper_list:\n",
    "    paper_url = (\n",
    "        \"https://scholar.google.com\"\n",
    "        + paper.find(name=\"a\", attrs={\"class\": \"gsc_a_at\"}).attrs[\"href\"]\n",
    "    )\n",
    "    paper_html = get(paper_url)\n",
    "    paper_dict = paper_soup2dict(paper_html)\n",
    "    paper_dict_list.append(paper_dict)\n",
    "pickle.dump(paper_dict_list, open(\"dump.txt\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get paper versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Stochastic distributed learning with gradient quantization and double-variance reduction\n",
      "1 Donâ€™t jump through hoops and remove those loops: SVRG and Katyusha are better without the outer loop\n",
      "2 Acceleration for compressed gradient descent in distributed and federated optimization\n",
      "3 From local SGD to local fixed-point methods for federated learning\n",
      "4 RSN: randomized subspace Newton\n",
      "5 Linearly converging error compensated SGD\n",
      "6 Revisiting stochastic extragradient\n",
      "7 Optimal and practical algorithms for smooth and strongly convex decentralized optimization\n",
      "8 A linearly convergent algorithm for decentralized optimization: Sending less bits for free!\n",
      "9 Accelerated methods for saddle-point problem\n",
      "10 Stochastic Newton and cubic Newton methods with simple local linear-quadratic rates\n",
      "11 Decentralized distributed optimization for saddle point problems\n",
      "12 Lower bounds and optimal algorithms for smooth and strongly convex decentralized optimization over time-varying networks\n",
      "13 Accelerated primal-dual gradient method for smooth and convex-concave saddle-point problems with bilinear coupling\n",
      "14 ADOM: accelerated decentralized optimization method for time-varying networks\n",
      "15 Optimal algorithms for decentralized stochastic variational inequalities\n",
      "16 On accelerated methods for saddle-point problems with composite structure\n",
      "17 The first optimal acceleration of high-order methods in smooth convex optimization\n",
      "18 Towards accelerated rates for distributed optimization over time-varying networks\n",
      "19 Stochastic proximal langevin algorithm: Potential splitting and nonasymptotic rates\n",
      "20 IntSGD: Adaptive floatless compression of stochastic gradients\n",
      "21 An optimal algorithm for strongly convex minimization under affine constraints\n",
      "22 Distributed fixed point methods with compressed iterates\n",
      "23 Smooth monotone stochastic variational inequalities and saddle point problems: A survey\n",
      "24 Optimal gradient sliding and its application to optimal distributed optimization under similarity\n",
      "25 The first optimal algorithm for smooth and strongly-convex-strongly-concave minimax optimization\n",
      "26 Variance reduced coordinate descent with acceleration: New method with a surprising application to finite-sum problems\n",
      "27 Fast linear convergence of randomized BFGS\n",
      "28 Near-optimal decentralized algorithms for saddle point problems over time-varying networks\n",
      "29 Stochastic spectral and conjugate descent methods\n",
      "30 Communication acceleration of local gradient methods via an accelerated primal-dual algorithm with an inexact prox\n",
      "31 Decentralized saddle-point problems with different constants of strong convexity and strong concavity\n",
      "32 Decentralized optimization over time-varying graphs: a survey\n",
      "33 Is consensus acceleration possible in decentralized optimization over slowly time-varying networks?\n",
      "34 On scaled methods for saddle point problems\n",
      "35 Decentralized convex optimization on time-varying networks with application to Wasserstein barycenters\n",
      "36 Non-smooth setting of stochastic decentralized convex optimization problem over time-varying graphs\n",
      "37 A hypothesis about the rate of global convergence for optimal methods (Newtonâ€™s type) in smooth convex optimization\n",
      "38 An optimal algorithm for strongly convex min-min optimization\n",
      "39 Decentralized saddle point problems via non-Euclidean mirror prox\n",
      "40 Decentralized Finite-Sum Optimization over Time-Varying Networks\n",
      "41 Optimal algorithm with complexity separation for strongly convex-strongly concave composite saddle point problems\n",
      "42 Accelerated variance-reduced methods for saddle-point problems\n",
      "43 Decentralized Optimization with Coupled Constraints\n",
      "44 Lower Bounds and Optimal Algorithms for Non-Smooth Convex Decentralized Optimization over Time-Varying Networks\n",
      "45 Decentralized Convex Optimization over Time-Varying Graphs\n",
      "46 Decentralized convex optimization over time-varying graphs: a survey\n",
      "47 Optimal Algorithms for Affinely Constrained, Distributed, Decentralized, Minimax, and High-Order Optimization Problems\n"
     ]
    }
   ],
   "source": [
    "paper_dict_list: typing.List[typing.Dict[str, bs4.Tag]] = pickle.load(\n",
    "    open(\"dump.txt\", \"rb\")\n",
    ")\n",
    "\n",
    "for i in range(len(paper_dict_list)):\n",
    "    print(i, paper_dict_list[i][\"Title\"].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url = https://scholar.google.com/scholar?start=0&num=100&hl=en&cluster=16969044896100418296 status = 200\n",
      "url = https://scholar.google.com/scholar?start=0&num=100&hl=en&cluster=15707566150174104807 status = 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://arxiv.org/abs/2102.08374',\n",
       " 'https://repository.kaust.edu.sa/handle/10754/667733',\n",
       " 'https://www.datascienceassn.org/sites/default/files/IntSGD%20Floatless%20Compression%20of%20Stochastic%20Gradients.pdf',\n",
       " 'https://ui.adsabs.harvard.edu/abs/2021arXiv210208374M/abstract',\n",
       " 'https://www.konstmish.com/uploads/slides/22-intsgd-slides.pdf',\n",
       " 'https://openreview.net/forum?id=pFyXqxChZc',\n",
       " 'https://repository.kaust.edu.sa/server/api/core/bitstreams/5849784f-31de-480c-a3ed-a80e47f2d376/content',\n",
       " 'https://repository.kaust.edu.sa/bitstreams/c2660e1d-6c39-4815-8bfe-71587f858327/download',\n",
       " 'https://repository.kaust.edu.sa/server/api/core/bitstreams/c2660e1d-6c39-4815-8bfe-71587f858327/content']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_version_urls(scholar_articles: bs4.Tag) -> typing.List[str]:\n",
    "    merged_snippet_list: bs4.ResultSet[bs4.Tag] = scholar_articles.find_all(\n",
    "        name=\"div\", attrs={\"class\": \"gsc_oci_merged_snippet\"}\n",
    "    )\n",
    "\n",
    "    version_url_list: typing.List[str] = []\n",
    "    for merged_snippet in merged_snippet_list:\n",
    "        link_list: bs4.ResultSet[bs4.Tag] = merged_snippet.find_all(name=\"a\")\n",
    "        version_href = link_list[-1].attrs[\"href\"]\n",
    "        version_cluster = urllib.parse.parse_qs(\n",
    "            urllib.parse.urlparse(version_href).query\n",
    "        )[\"cluster\"][0]\n",
    "        version_url = f\"https://scholar.google.com/scholar?start=0&num=100&hl=en&cluster={version_cluster}\"\n",
    "        version_url_list.append(version_url)\n",
    "    return version_url_list\n",
    "\n",
    "\n",
    "def extract_versions(scholar_articles: bs4.Tag):\n",
    "    url_list = extract_version_urls(scholar_articles)\n",
    "\n",
    "    version_list: typing.List[str] = []\n",
    "    for url in url_list:\n",
    "        soup = bs4.BeautifulSoup(get(url))\n",
    "        versions: bs4.ResultSet[bs4.Tag] = soup.find_all(attrs={\"class\": \"gs_rt\"})\n",
    "        for version in versions:\n",
    "            version_list.append(version.find(name=\"a\").attrs[\"href\"])\n",
    "    return version_list\n",
    "\n",
    "\n",
    "extract_versions(paper_dict_list[20][\"Scholar articles\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"gsc_oci_value\">\n",
      " <div class=\"gsc_oci_merged_snippet\">\n",
      "  <div>\n",
      "   <a href=\"/scholar?oi=bibs&amp;cluster=10432066948921138844&amp;btnI=1&amp;hl=en\">\n",
      "    Stochastic distributed learning with gradient quantization and double-variance reduction\n",
      "   </a>\n",
      "  </div>\n",
      "  <div>\n",
      "   S HorvÃ¡th, D Kovalev, K Mishchenko, P RichtÃ¡rikâ€¦Â - Optimization Methods and Software, 2023\n",
      "  </div>\n",
      "  <div>\n",
      "   <a class=\"gsc_oms_link\" href=\"https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10432066948921138844&amp;as_sdt=5\">\n",
      "    Cited by 180\n",
      "   </a>\n",
      "   <a class=\"gsc_oms_link\" href=\"https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;q=related:nJ6JW54lxpAJ:scholar.google.com/\">\n",
      "    Related articles\n",
      "   </a>\n",
      "   <a class=\"gsc_oms_link\" href=\"https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cluster=10432066948921138844\">\n",
      "    All 17 versions\n",
      "   </a>\n",
      "  </div>\n",
      " </div>\n",
      "</div>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "paper_dict = paper_dict_list[0]\n",
    "print(paper_dict[\"Scholar articles\"].prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10432066948921138844\n",
      "url = https://scholar.google.com/scholar?start=0&num=100&hl=en&cluster=10432066948921138844 status = 200\n"
     ]
    }
   ],
   "source": [
    "version_href = (\n",
    "    paper_dict[\"Scholar articles\"]\n",
    "    .find_all(name=\"a\", attrs={\"class\": \"gsc_oms_link\"})[-1]\n",
    "    .attrs[\"href\"]\n",
    ")\n",
    "version_cluster = urllib.parse.parse_qs(urllib.parse.urlparse(version_href).query)[\n",
    "    \"cluster\"\n",
    "][0]\n",
    "print(version_cluster)\n",
    "\n",
    "version_html = get(\n",
    "    f\"https://scholar.google.com/scholar?start=0&num=100&hl=en&cluster={version_cluster}\"\n",
    ")\n",
    "version_soup = bs4.BeautifulSoup(version_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "www.tandfonline.com https://www.tandfonline.com/doi/abs/10.1080/10556788.2022.2117355\n",
      "repository.kaust.edu.sa https://repository.kaust.edu.sa/bitstream/10754/653103/1/1904.05115.pdf\n",
      "dclibrary.mbzuai.ac.ae https://dclibrary.mbzuai.ac.ae/mlfp/359/\n",
      "arxiv.org https://arxiv.org/abs/1904.05115\n",
      "www.researchgate.net https://www.researchgate.net/profile/Samuel-Horvath-2/publication/332342206_Stochastic_Distributed_Learning_with_Gradient_Quantization_and_Variance_Reduction/links/5d359e724585153e5916c157/Stochastic-Distributed-Learning-with-Gradient-Quantization-and-Variance-Reduction.pdf\n",
      "ui.adsabs.harvard.edu https://ui.adsabs.harvard.edu/abs/2019arXiv190405115H/abstract\n",
      "2019.ds3-datascience-polytechnique.fr https://2019.ds3-datascience-polytechnique.fr/wp-content/uploads/2019/06/DS3-608_2019.pdf\n",
      "publications.cispa.saarland https://publications.cispa.saarland/id/eprint/3980\n",
      "www.ds3-datascience-polytechnique.fr https://www.ds3-datascience-polytechnique.fr/wp-content/uploads/2019/06/DS3-608_2019.pdf\n",
      "nchr.elsevierpure.com https://nchr.elsevierpure.com/en/publications/stochastic-distributed-learning-with-gradient-quantization-and-do\n",
      "core.ac.uk https://core.ac.uk/download/pdf/599569336.pdf\n",
      "www.ingentaconnect.com https://www.ingentaconnect.com/content/tandf/goms/2023/00000038/00000001/art00004\n",
      "publications.cispa.de https://publications.cispa.de/articles/journal_contribution/Stochastic_distributed_learning_with_gradient_quantization_and_double-variance_reduction/25469572\n",
      "infoscience.epfl.ch https://infoscience.epfl.ch/record/297436\n",
      "publications.cispa.de https://publications.cispa.de/ndownloader/files/45257332\n",
      "repository.kaust.edu.sa https://repository.kaust.edu.sa/items/e8e43ddb-362d-415c-9815-95432bbcb200\n",
      "publications.cispa.saarland https://publications.cispa.saarland/3980/\n"
     ]
    }
   ],
   "source": [
    "version_list: bs4.ResultSet[bs4.Tag] = version_soup.find_all(attrs={\"class\": \"gs_rt\"})\n",
    "\n",
    "for version in version_list:\n",
    "    version_url = version.find(name=\"a\").attrs[\"href\"]\n",
    "    print(urllib.parse.urlparse(version_url).netloc, version_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
