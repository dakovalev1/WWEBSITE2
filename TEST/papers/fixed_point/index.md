title: Distributed Fixed Point Methods with Compressed Iterates
abstract: We propose basic and natural assumptions under which iterative optimization methods with compressed iterates can be analyzed. This problem is motivated by the practice of federated learning, where a large model stored in the cloud is compressed before it is sent to a mobile device, which then proceeds with training based on local data. We develop standard and variance reduced methods, and establish communication complexity bounds. Our algorithms are the first distributed methods with compressed iterates, and the first fixed point methods with compressed iterates.
authors:Sélim Chraibi
        Ahmed Khaled
        Dmitry Kovalev
        Peter Richtárik
        Adil Salim
        Martin Takáč
date: 20 Dec 2019
links: {"PDF" : "https://arxiv.org/pdf/1912.09925.pdf", "arXiv" : "https://arxiv.org/abs/1912.09925"}